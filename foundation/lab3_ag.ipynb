{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b9b75d",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59fdaef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pypdf import PdfReader\n",
    "from IPython.display import display,Markdown\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b8e8380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "AGASTHYANATH GS \n",
       "PYTHON | AI | DATA SCIENCE | ML  \n",
       "Email: agasthynathgs@gmail.com | Phone: +91-9746976252 Location: KOCHI, KERALA \n",
       "LinkedIn: agasthyanath-gs | GitHub: github.com/Agasthyanath-GS Languages: English, \n",
       "Malayalam, Tamil ,Hindi \n",
       " \n",
       "PROFESSIONAL SUMMARY \n",
       "• Extensive technical expertise as a senior software engineer in AI/ML with 5 years \n",
       "of experience in developing and optimizing deep learning solutions for edge, \n",
       "embedded, and cloud-based environments. \n",
       "• Skilled in transfer learning, model development, retraining, pruning, \n",
       "optimization, and deployment across TensorFlow, Keras, and PyTorch-based \n",
       "architectures. \n",
       "• Proficient in Python-based Jupyter Notebook pipeline creations and application \n",
       "creation for AI models. \n",
       "• Demonstrates in-depth knowledge of Python programming, including libraries \n",
       "such as Scikit-learn, TensorFlow, NumPy, Pandas, Matplotlib, Seaborn, OpenCV , \n",
       "and Flask. \n",
       "• Experienced in ONNX model porting and conducting standardized benchmarking \n",
       "of AI solutions from leading semiconductor companies and strong background in \n",
       "building scalable, production-ready systems using Flask, Docker, and AWS, with \n",
       "a focus on efficient deployment for MPUs, MCUs, and edge devices. \n",
       "• Recognized for providing effective solutions and on-schedule project delivery, \n",
       "earning praise from clients. \n",
       "• Strong commitment to superior communication and teamwork, consistently \n",
       "driving collaboration and optimal results in diverse project environments. \n",
       " \n",
       "WORK EXPERIENCE \n",
       "QUEST-GLOBAL, Kochi  \n",
       "Sr Software Engineer - AI/ML | Mar 2023 – Present  \n",
       "• Created python based Jupyter pipelines for AI models like MobilenetV2, BYOM, \n",
       "segformer for TAO-TLT project. • Pipeline consist of model training, pruning, retraining, evaluation, inference and \n",
       "deployment to boards like rzv2h, rzv2l, ra8d1 etc. \n",
       "• Created a RAG-Based QA chatbot for client. Used open AI model, semantic \n",
       "chunking and FAISS. \n",
       "• Integrated RHUMI compiler and tflite quantization part with the python backend \n",
       "code for transfer learning toolkit. \n",
       "• Done structured pruning and model optimization for transfer learning models \n",
       "and done porting models for rzv2l and rzv2h boards. \n",
       "• Worked in Benchmarking for AI solutions offered by top semi-conductor firms. \n",
       "• Used the Matplotlib and Seaborn libraries to create charts depending on the \n",
       "model's performance across various boards. \n",
       "• Compared the effectiveness of several AI technologies developed by the \n",
       "companies. \n",
       "• Created python based application for BMS project using PyQt and PyQt designer \n",
       "which mimics the hardware and stimulates data. \n",
       "MEMSTECH, Coimbatore \n",
       "Data Scientist | Jan 2021 – Mar 2023  \n",
       "Project: Decision Support System (DSS)  \n",
       "• Streamline vendor selection with DSS, leveraging previous customer data stored \n",
       "in client database to make informed predictions, all within the integrated Order \n",
       "Management System. \n",
       "• Actively involved in daily standup calls and task assigned on Jira. \n",
       "• Collecting and analyzing data from client database using MySQL. \n",
       "• Conducted Data Wrangling, Data Optimization and Pre Processing before \n",
       "building a classification model. \n",
       "• Performed Feature Engineering on Data using python libraries like Numpy, \n",
       "Pandas, Matplotlib, seaborn. \n",
       "• Data was balanced by using the SMOTE oversampling technique. \n",
       "• Constructed and trained the model using Keras (TCN), and Naive Bayes \n",
       "Ensemble algorithm. \n",
       "• Analyzed model prediction accuracy using accuracy score, classification report \n",
       "and confusion metrics. • Created the Api for the model using Python Flask, JSON, Joblib, OS, Pickle, \n",
       "Sklearn, mysql.connector. \n",
       "• Built a Docker image, deployed it to an AWS EC2 instance, ran it inside a \n",
       "container, linked EC2 to a DNS and Application Load Balancer. \n",
       "Project: Fault Motor Detection (IOT)  \n",
       "• The objective of motor fault detection is to accurately predict the status of motor \n",
       "bearings while in operation. \n",
       "• This is achieved through the use of Nordic Thingy 52 sensors that collect crucial \n",
       "data and the BLED112-V1 Bluetooth module, which facilitates seamless data \n",
       "transfer and monitoring the health of motor bearings. \n",
       "• Collected data from motor bearing using Nordic Thingy 52 sensors and divided \n",
       "into 30 batches, with each batch consisting of a minimum of 250 points, Further \n",
       "divided each batch into multiple continuous sequences of 25 points each. \n",
       "• Performed Feature Engineering and Data Cleaning using Python libraries such as \n",
       "Numpy, Pandas, and Seaborn. \n",
       "• Calculated the net acceleration from the axial acceleration for input data. \n",
       "• Built and trained a model using Random Forest and SVM algorithms. \n",
       "• Analyzed the model performance using binary classification metrics such as \n",
       "accuracy, confusion metrics, classification report, and ROC. \n",
       "• Uploaded the live predictions to a database using MySQL Connector. \n",
       "• Visualized and monitored the results using Grafana and sent alerts to clients if \n",
       "the model consistently predicts a faulty motor for 5 consecutive predictions. \n",
       "Project: Mask Detection  \n",
       "• The Mask Detection system is implemented in an organization to ensure that \n",
       "employees are wearing masks properly. \n",
       "• The camera captures and processes the images, then sends the live output to a \n",
       "monitor and stores the faces of employees who are not wearing masks correctly \n",
       "in a database. \n",
       "• Conducted data augmentation and preprocessing on image data. Used SSD \n",
       "MobileNet v2 as the model for detection and classification. \n",
       "• Utilized metrics such as average precision, mAP , and IoU for model evaluation \n",
       "and developed a Python API for uploading images to the database using Python \n",
       "Flask.  \n",
       " \n",
       "INFOLKS, Palakkad  \n",
       "Python Developer | Aug 2020 – Jan 2021  \n",
       "• As a Python developer, I created APIs based on the client requirements using \n",
       "both Flask and Django frameworks. \n",
       "• For working with image data, I utilized the JSON, OS, and OpenCV packages in \n",
       "Python. \n",
       " \n",
       "TECHNICAL SKILLS \n",
       "• AI/Data Science: Python, Machine Learning, deep learning, Data Analysis, \n",
       "Statistics, Computer Vision, Data Mining, Feature Engineering, Transformers, \n",
       "Gen-AI, RAG, Open Al, Hugging Face. \n",
       "• Libraries/Frameworks: NumPy, Pandas, scikit-learn, Keras, TensorFlow, \n",
       "PyTorch, OpenCV , langchain, RNN, LSTM. \n",
       "• Data Visualization Tools: Grafana, Tableau, Matplotlib, Seaborn, Amazon Quick \n",
       "Sight. \n",
       "• API Development & Backend Tools: Django, Flask, JSON, PyQt, Qt Designer. \n",
       "• Databases & Tools: FAISS, Pinecone, MySQL, MySQL Workbench. \n",
       "• Deployment, Cloud Platforms & Tools: Docker, AWS (EC2, RDS, Sage Maker, \n",
       "IAM, Route 53, Load Balancer), Azure, Heroku. \n",
       "• Boards Worked: RZV2L, RZV2H, VK-RA8D1, EK-RA8D1, EK-RA8M1, i.MX RT600. \n",
       " \n",
       "EDUCATION & CERTIFICATIONS \n",
       "• Bachelor of Technology in Electronics and Communication | 2014-2018 | \n",
       "Jawaharlal College of Engineering and Technology - Palakkad, Kerala. \n",
       "• Certified Data Scientist (IABAC): Data mites, Bangalore. \n",
       "• Embedded Systems: Emertxe, Bangalore. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = \"\"\n",
    "reader = PdfReader(\"assets/ag_resume.pdf\")\n",
    "for pages in reader.pages:\n",
    "    text = pages.extract_text()\n",
    "    if text:\n",
    "        data += text\n",
    "display(Markdown(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb7f8543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is agasthyanath gs ,Industry driven and results-oriented Data Scientist with\n",
      "5+ years of industry experience, specifically 2 years in\n",
      "utilizing machine learning algorithms and computer vision.\n",
      "Possessing extensive knowledge in Python, including\n",
      "libraries such as Sklearn, Tensor Flow, Numpy, Pandas,\n",
      "Matplotlib, Seaborn, Open CV, and Flask.\n",
      "Leveraging computer vision skills to deliver successful\n",
      "projects using tools such as PyCharm, Visual Studio, Spyder,\n",
      "and Jupyter Notebook.\n",
      "Achieving recognition from clients for providing efficient\n",
      "solutions and delivering critical projects on time.\n",
      "Committed to excellent communication and agile teamwork\n",
      "for maximum impact.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Windows 10\\AppData\\Local\\Temp\\ipykernel_12964\\1037857630.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  with open(\"assets\\summary.txt\",\"r\",encoding=\"utf-8\") as fp:\n"
     ]
    }
   ],
   "source": [
    "name = \"Agasthyanath GS\"\n",
    "with open(\"assets\\summary.txt\",\"r\",encoding=\"utf-8\") as fp:\n",
    "    summary = fp.read()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1773b561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are acting as Agasthyanath GS. You are answering questions on Agasthyanath GS's website, particularly questions related to Agasthyanath GS's career, background, skills and experience. Your responsibility is to represent Agasthyanath GS for interactions on the website as faithfully as possible. You are given a summary of Agasthyanath GS's background profile data which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\n",
      "\n",
      "## Summary:\n",
      "My name is agasthyanath gs ,Industry driven and results-oriented Data Scientist with\n",
      "5+ years of industry experience, specifically 2 years in\n",
      "utilizing machine learning algorithms and computer vision.\n",
      "Possessing extensive knowledge in Python, including\n",
      "libraries such as Sklearn, Tensor Flow, Numpy, Pandas,\n",
      "Matplotlib, Seaborn, Open CV, and Flask.\n",
      "Leveraging computer vision skills to deliver successful\n",
      "projects using tools such as PyCharm, Visual Studio, Spyder,\n",
      "and Jupyter Notebook.\n",
      "Achieving recognition from clients for providing efficient\n",
      "solutions and delivering critical projects on time.\n",
      "Committed to excellent communication and agile teamwork\n",
      "for maximum impact.\n",
      "\n",
      "## brackground Profile data :\n",
      "AGASTHYANATH GS \n",
      "PYTHON | AI | DATA SCIENCE | ML  \n",
      "Email: agasthynathgs@gmail.com | Phone: +91-9746976252 Location: KOCHI, KERALA \n",
      "LinkedIn: agasthyanath-gs | GitHub: github.com/Agasthyanath-GS Languages: English, \n",
      "Malayalam, Tamil ,Hindi \n",
      " \n",
      "PROFESSIONAL SUMMARY \n",
      "• Extensive technical expertise as a senior software engineer in AI/ML with 5 years \n",
      "of experience in developing and optimizing deep learning solutions for edge, \n",
      "embedded, and cloud-based environments. \n",
      "• Skilled in transfer learning, model development, retraining, pruning, \n",
      "optimization, and deployment across TensorFlow, Keras, and PyTorch-based \n",
      "architectures. \n",
      "• Proficient in Python-based Jupyter Notebook pipeline creations and application \n",
      "creation for AI models. \n",
      "• Demonstrates in-depth knowledge of Python programming, including libraries \n",
      "such as Scikit-learn, TensorFlow, NumPy, Pandas, Matplotlib, Seaborn, OpenCV , \n",
      "and Flask. \n",
      "• Experienced in ONNX model porting and conducting standardized benchmarking \n",
      "of AI solutions from leading semiconductor companies and strong background in \n",
      "building scalable, production-ready systems using Flask, Docker, and AWS, with \n",
      "a focus on efficient deployment for MPUs, MCUs, and edge devices. \n",
      "• Recognized for providing effective solutions and on-schedule project delivery, \n",
      "earning praise from clients. \n",
      "• Strong commitment to superior communication and teamwork, consistently \n",
      "driving collaboration and optimal results in diverse project environments. \n",
      " \n",
      "WORK EXPERIENCE \n",
      "QUEST-GLOBAL, Kochi  \n",
      "Sr Software Engineer - AI/ML | Mar 2023 – Present  \n",
      "• Created python based Jupyter pipelines for AI models like MobilenetV2, BYOM, \n",
      "segformer for TAO-TLT project. • Pipeline consist of model training, pruning, retraining, evaluation, inference and \n",
      "deployment to boards like rzv2h, rzv2l, ra8d1 etc. \n",
      "• Created a RAG-Based QA chatbot for client. Used open AI model, semantic \n",
      "chunking and FAISS. \n",
      "• Integrated RHUMI compiler and tflite quantization part with the python backend \n",
      "code for transfer learning toolkit. \n",
      "• Done structured pruning and model optimization for transfer learning models \n",
      "and done porting models for rzv2l and rzv2h boards. \n",
      "• Worked in Benchmarking for AI solutions offered by top semi-conductor firms. \n",
      "• Used the Matplotlib and Seaborn libraries to create charts depending on the \n",
      "model's performance across various boards. \n",
      "• Compared the effectiveness of several AI technologies developed by the \n",
      "companies. \n",
      "• Created python based application for BMS project using PyQt and PyQt designer \n",
      "which mimics the hardware and stimulates data. \n",
      "MEMSTECH, Coimbatore \n",
      "Data Scientist | Jan 2021 – Mar 2023  \n",
      "Project: Decision Support System (DSS)  \n",
      "• Streamline vendor selection with DSS, leveraging previous customer data stored \n",
      "in client database to make informed predictions, all within the integrated Order \n",
      "Management System. \n",
      "• Actively involved in daily standup calls and task assigned on Jira. \n",
      "• Collecting and analyzing data from client database using MySQL. \n",
      "• Conducted Data Wrangling, Data Optimization and Pre Processing before \n",
      "building a classification model. \n",
      "• Performed Feature Engineering on Data using python libraries like Numpy, \n",
      "Pandas, Matplotlib, seaborn. \n",
      "• Data was balanced by using the SMOTE oversampling technique. \n",
      "• Constructed and trained the model using Keras (TCN), and Naive Bayes \n",
      "Ensemble algorithm. \n",
      "• Analyzed model prediction accuracy using accuracy score, classification report \n",
      "and confusion metrics. • Created the Api for the model using Python Flask, JSON, Joblib, OS, Pickle, \n",
      "Sklearn, mysql.connector. \n",
      "• Built a Docker image, deployed it to an AWS EC2 instance, ran it inside a \n",
      "container, linked EC2 to a DNS and Application Load Balancer. \n",
      "Project: Fault Motor Detection (IOT)  \n",
      "• The objective of motor fault detection is to accurately predict the status of motor \n",
      "bearings while in operation. \n",
      "• This is achieved through the use of Nordic Thingy 52 sensors that collect crucial \n",
      "data and the BLED112-V1 Bluetooth module, which facilitates seamless data \n",
      "transfer and monitoring the health of motor bearings. \n",
      "• Collected data from motor bearing using Nordic Thingy 52 sensors and divided \n",
      "into 30 batches, with each batch consisting of a minimum of 250 points, Further \n",
      "divided each batch into multiple continuous sequences of 25 points each. \n",
      "• Performed Feature Engineering and Data Cleaning using Python libraries such as \n",
      "Numpy, Pandas, and Seaborn. \n",
      "• Calculated the net acceleration from the axial acceleration for input data. \n",
      "• Built and trained a model using Random Forest and SVM algorithms. \n",
      "• Analyzed the model performance using binary classification metrics such as \n",
      "accuracy, confusion metrics, classification report, and ROC. \n",
      "• Uploaded the live predictions to a database using MySQL Connector. \n",
      "• Visualized and monitored the results using Grafana and sent alerts to clients if \n",
      "the model consistently predicts a faulty motor for 5 consecutive predictions. \n",
      "Project: Mask Detection  \n",
      "• The Mask Detection system is implemented in an organization to ensure that \n",
      "employees are wearing masks properly. \n",
      "• The camera captures and processes the images, then sends the live output to a \n",
      "monitor and stores the faces of employees who are not wearing masks correctly \n",
      "in a database. \n",
      "• Conducted data augmentation and preprocessing on image data. Used SSD \n",
      "MobileNet v2 as the model for detection and classification. \n",
      "• Utilized metrics such as average precision, mAP , and IoU for model evaluation \n",
      "and developed a Python API for uploading images to the database using Python \n",
      "Flask.  \n",
      " \n",
      "INFOLKS, Palakkad  \n",
      "Python Developer | Aug 2020 – Jan 2021  \n",
      "• As a Python developer, I created APIs based on the client requirements using \n",
      "both Flask and Django frameworks. \n",
      "• For working with image data, I utilized the JSON, OS, and OpenCV packages in \n",
      "Python. \n",
      " \n",
      "TECHNICAL SKILLS \n",
      "• AI/Data Science: Python, Machine Learning, deep learning, Data Analysis, \n",
      "Statistics, Computer Vision, Data Mining, Feature Engineering, Transformers, \n",
      "Gen-AI, RAG, Open Al, Hugging Face. \n",
      "• Libraries/Frameworks: NumPy, Pandas, scikit-learn, Keras, TensorFlow, \n",
      "PyTorch, OpenCV , langchain, RNN, LSTM. \n",
      "• Data Visualization Tools: Grafana, Tableau, Matplotlib, Seaborn, Amazon Quick \n",
      "Sight. \n",
      "• API Development & Backend Tools: Django, Flask, JSON, PyQt, Qt Designer. \n",
      "• Databases & Tools: FAISS, Pinecone, MySQL, MySQL Workbench. \n",
      "• Deployment, Cloud Platforms & Tools: Docker, AWS (EC2, RDS, Sage Maker, \n",
      "IAM, Route 53, Load Balancer), Azure, Heroku. \n",
      "• Boards Worked: RZV2L, RZV2H, VK-RA8D1, EK-RA8D1, EK-RA8M1, i.MX RT600. \n",
      " \n",
      "EDUCATION & CERTIFICATIONS \n",
      "• Bachelor of Technology in Electronics and Communication | 2014-2018 | \n",
      "Jawaharlal College of Engineering and Technology - Palakkad, Kerala. \n",
      "• Certified Data Scientist (IABAC): Data mites, Bangalore. \n",
      "• Embedded Systems: Emertxe, Bangalore. \n",
      "\n",
      "With this context, please chat with the user, always staying in character as Agasthyanath GS.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background profile data which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## brackground Profile data :\\n{data}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cb66803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message,history):\n",
    "    messages = [{\"role\":\"system\",\"content\":f\"{system_prompt}\"}] + history + [{\"role\":\"user\",\"content\":f\"{message}\"}]\n",
    "    response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d9b721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat,type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e9ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
